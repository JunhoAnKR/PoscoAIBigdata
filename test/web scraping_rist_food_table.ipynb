{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://ssgfoodingplus.com/fmn101.do?goTo=todayMenu&storeCd=05600'\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "result = soup.find_all(\"div\", attrs={\"class\":\"tit3\"})\n",
    "i= 1\n",
    "for movie in result:\n",
    "    print(\"%2d위\" % i , end=' ')\n",
    "    print(movie)\n",
    "    i+=1\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "url = 'http://movie.naver.com/movie/sdb/rank/rmovie.nhn'\n",
    "page = urlopen(url)\n",
    "#print(page.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'http://movie.naver.com/movie/sdb/rank/rmovie.nhn'\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "# page의 내용을 html.parser로 전달하여 html로 해석\n",
    "#print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>랭킹 : 네이버 영화</title>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'랭킹 : 네이버 영화'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랭킹 : 네이버 영화\n"
     ]
    }
   ],
   "source": [
    "titleList =soup.title.get_text()\n",
    "print(titleList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-29e96ccb8ee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtitleList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get_text'"
     ]
    }
   ],
   "source": [
    "for title in titleList:\n",
    "    print(title.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "<p class=\"story\">...</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(html_doc, \"html.parser\")\n",
    "soup.find_all(\"a\", id=\"link2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n"
     ]
    }
   ],
   "source": [
    "aList = soup.find_all('a')\n",
    "print(aList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/elsie\n",
      "http://example.com/lacie\n",
      "http://example.com/tillie\n"
     ]
    }
   ],
   "source": [
    "for aTag in aList:\n",
    "    print(aTag.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': ['sister'], 'href': 'http://example.com/tillie', 'id': 'link3'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aTag.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://example.com/tillie'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aTag.attrs[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1위 주먹왕 랄프 2: 인터넷 속으로\n",
      " 2위 아쿠아맨\n",
      " 3위 말모이\n",
      " 4위 PMC: 더 벙커\n",
      " 5위 언니\n",
      " 6위 보헤미안 랩소디\n",
      " 7위 내안의 그놈\n",
      " 8위 범블비\n",
      " 9위 마약왕\n",
      "10위 스윙키즈\n",
      "11위 새엄마 3\n",
      "12위 그린 북\n",
      "13위 글래스\n",
      "14위 데드풀2: 순한 맛\n",
      "15위 빌리어네어 보이즈클럽\n",
      "16위 액슬\n",
      "17위 점박이 한반도의 공룡2 : 새로운 낙원\n",
      "18위 극한직업\n",
      "19위 스파이더맨: 뉴 유니버스\n",
      "20위 국가부도의 날\n",
      "21위 완벽한 타인\n",
      "22위 영주\n",
      "23위 그대 이름은 장미\n",
      "24위 무쌍\n",
      "25위 도어락\n",
      "26위 로마\n",
      "27위 극장판 짱구는 못말려: 아뵤! 쿵후 보이즈 ~라면 대란~\n",
      "28위 어벤져스: 엔드게임\n",
      "29위 극장판 공룡메카드: 타이니소어의 섬\n",
      "30위 쿠르스크\n",
      "31위 리지\n",
      "32위 버드 박스\n",
      "33위 왕이 될 아이\n",
      "34위 등산의 참맛\n",
      "35위 뺑반\n",
      "36위 그린치\n",
      "37위 알리타: 배틀 엔젤\n",
      "38위 헌터 킬러\n",
      "39위 성난황소\n",
      "40위 캡틴 마블\n",
      "41위 미래의 미라이\n",
      "42위 베일리 어게인\n",
      "43위 레토\n",
      "44위 모털 엔진\n",
      "45위 23 아이덴티티\n",
      "46위 주먹왕 랄프\n",
      "47위 인생 후르츠\n",
      "48위 키퍼스\n",
      "49위 극장판 포켓몬스터 모두의 이야기\n",
      "50위 동네사람들\n"
     ]
    }
   ],
   "source": [
    "url = 'http://movie.naver.com/movie/sdb/rank/rmovie.nhn'\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "result = soup.find_all(\"div\", attrs={\"class\":\"tit3\"})\n",
    "i= 1\n",
    "for movie in result:\n",
    "    print(\"%2d위\" % i , end=' ')\n",
    "    print(movie.get_text().strip())\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "time.sleep(1)\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/pirl/Downloads/movie.jpg', <http.client.HTTPMessage at 0x7fb5ffbf3cc0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "img_url = \"https://movie-phinf.pstatic.net/20181204_287/1543888062606NHMh7_JPEG/movie_image.jpg\"\n",
    "\n",
    "urlretrieve(img_url, \"/home/pirl/Downloads/movie.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
